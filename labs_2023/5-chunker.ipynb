{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x147fb5cd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "def closest(target_word, embeddings, count=10):\n",
    "    unsorted = {}\n",
    "    for word, _ in embeddings.items():\n",
    "        unsorted[word] = cosine_similarity(target_word, word, embeddings)\n",
    "\n",
    "    sorted_list = sorted(unsorted.items(), key=lambda item: -item[1])\n",
    "    sorted_list_no_value = [word for word, value in sorted_list]\n",
    "    return sorted_list_no_value[:count]\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def cosine_similarity(target, other, embeddings):\n",
    "    #cosine similarity = (A, B) = (A ⋅ B) / (||A|| * ||B||)\n",
    "    \n",
    "    target_array = embeddings[target]\n",
    "    other_array = embeddings[other]\n",
    "    \n",
    "    dot_product = np.dot(target_array, other_array)\n",
    "    target_magnitude = np.linalg.norm(target_array)\n",
    "    other_magnitude = np.linalg.norm(other_array)\n",
    "    \n",
    "    similarity = dot_product / (target_magnitude * other_magnitude)\n",
    "    return similarity\n",
    "\n",
    "closest('france', embeddings_dict)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest('france', embeddings_dict)\n",
    "# ['france',\n",
    "#  'belgium',\n",
    "#  'french',\n",
    "#  'britain',\n",
    "#  'spain',\n",
    "#  'paris',\n",
    "#  'germany',\n",
    "#  'italy',\n",
    "#  'europe',\n",
    "#  'netherlands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest('sweden', embeddings_dict)\n",
    "# ['sweden',\n",
    "#  'denmark',\n",
    "#  'norway',\n",
    "#  'finland',\n",
    "#  'netherlands',\n",
    "#  'austria',\n",
    "#  'switzerland',\n",
    "#  'germany',\n",
    "#  'swedish',\n",
    "#  'belgium']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n",
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for sentence_data in corpus_dict:\n",
    "        x = []\n",
    "        y = []\n",
    "        for word_data in sentence_data:\n",
    "            x += [word_data[key_x]]\n",
    "            y += [word_data[key_y]]\n",
    "\n",
    "\n",
    "        if(tolower):\n",
    "            x = list(map(lambda word: word.lower(), x))\n",
    "        X += [x]\n",
    "        Y += [y]\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')\n",
    "print(X_train_symbs[10])\n",
    "print(Y_train_symbs[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words = []\n",
    "for sentence in X_train_symbs:\n",
    "    for word in sentence:\n",
    "        if word not in words:\n",
    "            words += [word]\n",
    "words.sort()\n",
    "\n",
    "chunks = []\n",
    "for sentence in Y_train_symbs:\n",
    "    for symbol in sentence:\n",
    "        if symbol not in chunks:\n",
    "            chunks += [symbol]\n",
    "chunks.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))\n",
    "# words seen in training corpus: 17258\n",
    "# Chunks tags seen: 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]\n",
    "# ['casinos',\n",
    "#  'caspita',\n",
    "#  'caspita-brand',\n",
    "#  'cassettes',\n",
    "#  'cast',\n",
    "#  'castigated',\n",
    "#  'castigating',\n",
    "#  'castillo',\n",
    "#  'casting',\n",
    "#  'castro-medellin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = list(set(words + embedded_words))\n",
    "vocabulary_words.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))\n",
    "## words in the vocabulary: embeddings and corpus: 401464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]\n",
    "# ['joy',\n",
    "#  'joya',\n",
    "#  'joyal',\n",
    "#  'joyandet',\n",
    "#  'joyas',\n",
    "#  'joyce',\n",
    "#  'joycean',\n",
    "#  'joycelyn',\n",
    "#  'joyces',\n",
    "#  'joydeep']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code:\n",
    "\n",
    "numbers =list(range(0, len(vocabulary_words) + 2))\n",
    "\n",
    "word2idx = dict(zip(vocabulary_words, numbers[2:]))\n",
    "chunk2idx = dict(zip(chunks, numbers[1:]))\n",
    "\n",
    "idx2word = {value: key for key, value in word2idx.items()}\n",
    "idx2chunk = {value: key for key, value in chunk2idx.items()}\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])\n",
    "#[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)\n",
    "#{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word not in embeddings_dict.keys():\n",
    "        out_of_embeddings += [word]\n",
    "    else:\n",
    "        temp = embedding_matrix[word2idx[word]]\n",
    "        temp2 = embeddings_dict[word]\n",
    "        embedding_matrix[word2idx[word]] = embeddings_dict[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)\n",
    "#1464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]\n",
    "# [\"y'all\",\n",
    "#  'yankus',\n",
    "#  'year-ago',\n",
    "#  'year-before',\n",
    "#  'year-earlier',\n",
    "#  'year-to-date',\n",
    "#  'yield-management',\n",
    "#  'zaishuo',\n",
    "#  'zarett',\n",
    "#  'zumbrunn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]\n",
    "# array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
    "#        -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]\n",
    "# array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
    "#         0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    x_numerical = []\n",
    "    for word in x:\n",
    "        x_numerical.append(word2idx[word])\n",
    "    X_train_idx += [x_numerical]\n",
    "\n",
    "    y_numerical = []\n",
    "    for chunk in y:\n",
    "        y_numerical.append(chunk2idx[chunk])\n",
    "    Y_train_idx += [y_numerical]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])\n",
    "#[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])\n",
    "#[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]\n",
    "# tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "#         362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "#          43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "#              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "#              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "#              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "#              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "#              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "#              0,      0,      0,      0,      0,      0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]\n",
    "# tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "#          6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "#          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "#          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "#          0,  0,  0,  0,  0,  0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(torch.from_numpy(embedding_matrix).float(), padding_idx = 0)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, batch_first=True, bidirectional=bidi_lstm)\n",
    "        \n",
    "        if not bidi_lstm:\n",
    "            self.fc = nn.Linear(lstm_units, nbr_classes)\n",
    "        else:\n",
    "            # twice the units if bidirectional \n",
    "            self.fc = nn.Linear(2*lstm_units, nbr_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.embeddings(sentence)\n",
    "        #embeds = self.dropout(embeds)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        lstm_out = F.relu(lstm_out)\n",
    "        #lstm_out = self.dropout(lstm_out)\n",
    "        logits = self.fc(lstm_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1\n",
    "# Model(\n",
    "#   (embeddings): Embedding(401466, 100, padding_idx=0)\n",
    "#   (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
    "#   (fc): Linear(in_features=256, out_features=23, bias=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "#loss_fn = ...\n",
    "#optimizer = ...\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)    # cross entropy loss\n",
    "optimizer = torch.optim.RMSprop(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()\n",
    "#torch.Size([8936, 78])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)\n",
    "#tensor([6, 7, 6,  ..., 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()\n",
    "#torch.Size([697008])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()\n",
    "#torch.Size([8936, 78, 23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()\n",
    "#torch.Size([697008, 23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:15<00:00, 18.41it/s]\n",
      "100%|██████████| 280/280 [00:14<00:00, 18.87it/s]\n",
      "100%|██████████| 280/280 [00:15<00:00, 18.09it/s]\n",
      "100%|██████████| 280/280 [00:15<00:00, 18.09it/s]\n",
      "100%|██████████| 280/280 [00:14<00:00, 18.84it/s]\n",
      "100%|██████████| 280/280 [00:14<00:00, 18.97it/s]\n",
      "100%|██████████| 280/280 [00:14<00:00, 18.78it/s]\n",
      "100%|██████████| 280/280 [00:14<00:00, 18.73it/s]\n",
      "100%|██████████| 280/280 [00:14<00:00, 18.93it/s]\n",
      "100%|██████████| 280/280 [00:14<00:00, 18.92it/s]\n",
      "100%|██████████| 280/280 [00:14<00:00, 19.23it/s]\n",
      "100%|██████████| 280/280 [00:14<00:00, 19.06it/s]\n",
      "100%|██████████| 280/280 [00:14<00:00, 18.92it/s]\n",
      "100%|██████████| 280/280 [00:15<00:00, 18.46it/s]\n",
      "100%|██████████| 280/280 [00:15<00:00, 18.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGxCAYAAACwbLZkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0xklEQVR4nO3de1zUdb7H8fc4yHCJi5dEEERbDU1NEzYTMnVLOlqtPjimZZJlnXS3i6Rb6trVStJdk3ZbLHcrH7Xp0klqO621SwWKx24iVrvZ7YiBiEtagWmCDr/zxyyzjlxkEOYLzOv5eMyD5sv395vPsLPw9vv7fr8/m2VZlgAAAAzpZroAAADg3wgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMII0AHY7PZWvQoKCg4o9d54IEHZLPZWnVsQUFBm9TQ2V4bQPsIMF0AAE/vvPOOx/OHHnpI+fn5evvttz3azzvvvDN6nZtvvln/8R//0apjR48erXfeeeeMawAAiTACdDgXXXSRx/Ozzz5b3bp1a9B+qqNHjyokJKTFrxMbG6vY2NhW1RgeHn7aegCgpbhMA3RCEyZM0PDhw7V161YlJycrJCREc+fOlSTl5OQoNTVV0dHRCg4O1tChQ7VkyRIdOXLE4xyNXaYZMGCArrzySr3xxhsaPXq0goODNWTIED3zzDMe/Rq7VHLDDTforLPO0pdffqkpU6borLPOUlxcnBYtWqSamhqP4/ft26fp06crLCxMkZGRuu666/TBBx/IZrNp/fr1rfqZvPrqqxo7dqxCQkIUFhamSZMmNRhl+vrrr3XLLbcoLi5ODodDZ599tlJSUvTmm2+6+xQXF+vKK69Unz595HA4FBMToyuuuEL79u1z97EsS9nZ2Ro1apSCg4PVo0cPTZ8+XXv27PF4vZacCwAjI0CnVVFRodmzZ+vuu+/WihUr1K2b698WX3zxhaZMmaKMjAyFhobq008/1cqVK/X+++83uNTTmA8//FCLFi3SkiVLFBUVpT/84Q+66aabNGjQIF1yySXNHnv8+HH99Kc/1U033aRFixZp69ateuihhxQREaH77rtPknTkyBFNnDhR33zzjVauXKlBgwbpjTfe0MyZM1v9s9iwYYOuu+46paamauPGjaqpqdGqVas0YcIEvfXWW7r44oslSenp6dq5c6ceeeQRnXvuufruu++0c+dOHTp0yF3bpEmTNHDgQP3ud79TVFSUDhw4oPz8fB0+fNj9evPmzdP69et1xx13aOXKlfrmm2+0fPlyJScn68MPP1RUVFSLzwVAkgWgQ5szZ44VGhrq0TZ+/HhLkvXWW281e2xdXZ11/Phxa8uWLZYk68MPP3R/7/7777dO/RUQHx9vBQUFWV999ZW77YcffrB69uxpzZs3z92Wn59vSbLy8/M96pRkvfjiix7nnDJlipWQkOB+/rvf/c6SZL3++use/ebNm2dJsp599tlm39Opr+10Oq2YmBhrxIgRltPpdPc7fPiw1adPHys5OdnddtZZZ1kZGRlNnnvHjh2WJOuVV15pss8777xjSbJWr17t0V5WVmYFBwdbd999d4vPBcCFyzRAJ9WjRw/95Cc/adC+Z88ezZo1S3379pXdblf37t01fvx4SdLu3btPe95Ro0apf//+7udBQUE699xz9dVXX532WJvNpquuusqj7fzzz/c4dsuWLQoLC2swefbaa6897fkb89lnn2n//v1KT093jw5J0llnnaX//M//1LvvvqujR49Kki688EKtX79eDz/8sN59910dP37c41yDBg1Sjx49tHjxYj355JP65JNPGrzea6+9JpvNptmzZ+vEiRPuR9++fTVy5Ej3pauWnAuAC2EE6KSio6MbtH3//fcaN26c3nvvPT388MMqKCjQBx98oNzcXEnSDz/8cNrz9urVq0Gbw+Fo0bEhISEKCgpqcOyxY8fczw8dOqSoqKgGxzbW1hL1l1ga+3nExMSorq5O3377rSTXfJo5c+boD3/4g8aOHauePXvq+uuv14EDByRJERER2rJli0aNGqVf/vKXGjZsmGJiYnT//fe7g8s///lPWZalqKgode/e3ePx7rvv6uDBgy0+FwAX5owAnVRje4S8/fbb2r9/vwoKCtyjIZL03Xff+bCy5vXq1Uvvv/9+g/b6QNCa80muOTSn2r9/v7p166YePXpIknr37q2srCxlZWWptLRUr776qpYsWaLKykq98cYbkqQRI0boT3/6kyzL0kcffaT169dr+fLlCg4O1pIlS9S7d2/ZbDYVFhbK4XA0eM2T2053LgAujIwAXUh9QDn1j+RTTz1lopxGjR8/XocPH9brr7/u0f6nP/2pVedLSEhQv379tGHDBlmW5W4/cuSINm3a5F5hc6r+/fvrtttu06RJk7Rz584G37fZbBo5cqTWrFmjyMhId58rr7xSlmWpvLxcSUlJDR4jRoxo8bkAuDAyAnQhycnJ6tGjh+bPn6/7779f3bt31wsvvKAPP/zQdGluc+bM0Zo1azR79mw9/PDDGjRokF5//XX99a9/lSSPeR8t0a1bN61atUrXXXedrrzySs2bN081NTX61a9+pe+++06PPvqoJKmqqkoTJ07UrFmzNGTIEIWFhemDDz7QG2+8obS0NEmu+SDZ2dmaNm2azjnnHFmWpdzcXH333XeaNGmSJCklJUW33HKLbrzxRu3YsUOXXHKJQkNDVVFRoW3btmnEiBH62c9+1qJzAXAhjABdSK9evfSXv/xFixYt0uzZsxUaGqqpU6cqJydHo0ePNl2eJCk0NFRvv/22MjIydPfdd8tmsyk1NVXZ2dmaMmWKIiMjvT7nrFmzFBoaqszMTM2cOVN2u10XXXSR8vPzlZycLMk1EXfMmDF6/vnntXfvXh0/flz9+/fX4sWLdffdd0uSBg8erMjISK1atUr79+9XYGCgEhIStH79es2ZM8f9ek899ZQuuugiPfXUU8rOzlZdXZ1iYmKUkpKiCy+80KtzAZBs1snjmgBgyIoVK3TPPfeotLS01TvDAuicGBkB4HNPPPGEJGnIkCE6fvy43n77bf3mN7/R7NmzCSKAHyKMAPC5kJAQrVmzRnv37lVNTY37csk999xjujQABnCZBgAAGMXSXgAAYBRhBAAAGEUYAQAARnWKCax1dXXav3+/wsLCGt0CGwAAdDyWZenw4cOKiYlpdkPDThFG9u/fr7i4ONNlAACAVigrK2t22X6nCCNhYWGSXG8mPDzccDUAAKAlqqurFRcX5/473pROEUbqL82Eh4cTRgAA6GRON8WCCawAAMCoVoWR7OxsDRw4UEFBQUpMTFRhYWGTfW+44QbZbLYGj2HDhrW6aAAA0HV4HUZycnKUkZGhZcuWqbi4WOPGjdPkyZNVWlraaP/HH39cFRUV7kdZWZl69uypq6+++oyLBwAAnZ/X28GPGTNGo0eP1tq1a91tQ4cO1bRp05SZmXna41955RWlpaWppKRE8fHxjfapqalRTU2N+3n9BJiqqirmjACAIZZl6cSJE3I6naZLQQdht9sVEBDQ5JyQ6upqRUREnPbvt1cTWGtra1VUVKQlS5Z4tKempmr79u0tOsfTTz+tyy67rMkgIkmZmZl68MEHvSkNANCOamtrVVFRoaNHj5ouBR1MSEiIoqOjFRgY2OpzeBVGDh48KKfTqaioKI/2qKgoHThw4LTHV1RU6PXXX9eGDRua7bd06VItXLjQ/bx+ZAQA4Ht1dXUqKSmR3W5XTEyMAgMD2YASsixLtbW1+vrrr1VSUqLBgwc3u7FZc1q1tPfUD6FlWS36YK5fv16RkZGaNm1as/0cDoccDkdrSgMAtLHa2lrV1dUpLi5OISEhpstBBxIcHKzu3bvrq6++Um1trYKCglp1Hq8iTO/evWW32xuMglRWVjYYLTmVZVl65plnlJ6efkZDOQAAM1r7r150bW3xufDqDIGBgUpMTFReXp5He15enpKTk5s9dsuWLfryyy910003eV9lO3A6pYICaeNG11fmYwEAYIbXl2kWLlyo9PR0JSUlaezYsVq3bp1KS0s1f/58Sa75HuXl5Xruuec8jnv66ac1ZswYDR8+vG0qPwO5udKCBdK+ff9ui42VHn9cSkszVxcAAP7I67GVmTNnKisrS8uXL9eoUaO0detWbd682b06pqKiosGeI1VVVdq0aVOHGBXJzZWmT/cMIpJUXu5qz801UxcAdHVdYUR6woQJysjIaHH/vXv3ymazadeuXe1WkyQVFBTIZrPpu+++a9fXaS9e7zNiQkvXKZ+O0ykNGNAwiNSz2VwjJCUlkt3e6pcBgC7l2LFjKikpce+83Rq+HpE+3aKKOXPmaP369V6f95tvvlH37t1Pe+O3ek6nU19//bV69+6tgID2ux1cQUGBJk6cqG+//VaRkZHt9jqNae7z0S77jHR2hYVNBxFJsiyprMzVb8IEn5UFAF1a/Yj0qf/0rR+Rfumltg8kFRUV7v/OycnRfffdp88++8zdFhwc7NH/+PHj6t69+2nP27NnT6/qsNvt6tu3r1fH+CO/mhp90mezTfoBAJrndLpGRBobg69vy8ho+0s2ffv2dT8iIiJks9ncz48dO6bIyEi9+OKLmjBhgoKCgvTHP/5Rhw4d0rXXXqvY2FiFhIRoxIgR2rhxo8d5T71MM2DAAK1YsUJz585VWFiY+vfvr3Xr1rm/f+plmvrLKW+99ZaSkpIUEhKi5ORkj6AkSQ8//LD69OmjsLAw3XzzzVqyZIlGjRrl1c9g06ZNGjZsmBwOhwYMGKDVq1d7fD87O1uDBw9WUFCQoqKiNH36dPf3XnrpJY0YMULBwcHq1auXLrvsMh05csSr1/eGX4WR6Oi27QcAaJ43I9K+tnjxYt1xxx3avXu3Lr/8ch07dkyJiYl67bXX9Pe//1233HKL0tPT9d577zV7ntWrVyspKUnFxcX6+c9/rp/97Gf69NNPmz1m2bJlWr16tXbs2KGAgADNnTvX/b0XXnhBjzzyiFauXKmioiL179/f4xYsLVFUVKQZM2bommuu0ccff6wHHnhA9957r/vS1I4dO3THHXdo+fLl+uyzz/TGG2/okksukeQaVbr22ms1d+5c7d69WwUFBUpLS1O7zuqwOoGqqipLklVVVXVG5zlxwrJiYy3LZrMs1/8FPB82m2XFxbn6AQBcfvjhB+uTTz6xfvjhB6+P3bCh8d+3pz42bGiHwv/l2WeftSIiItzPS0pKLElWVlbWaY+dMmWKtWjRIvfz8ePHWwsWLHA/j4+Pt2bPnu1+XldXZ/Xp08dau3atx2sVFxdblmVZ+fn5liTrzTffdB/zl7/8xZLk/vmOGTPGuvXWWz3qSElJsUaOHNlknfXn/fbbby3LsqxZs2ZZkyZN8uhz1113Weedd55lWZa1adMmKzw83Kqurm5wrqKiIkuStXfv3iZf72TNfT5a+vfbr0ZG7HbXZCnJNVn1ZPXPs7KYvAoAbaUjj0gnJSV5PHc6nXrkkUd0/vnnq1evXjrrrLP0t7/9rcm70tc7//zz3f9dfzmosrKyxcdE/+vN1x/z2Wef6cILL/Tof+rz09m9e7dSUlI82lJSUvTFF1/I6XRq0qRJio+P1znnnKP09HS98MIL7vsOjRw5UpdeeqlGjBihq6++Wr///e/17bffevX63vKrMCK5Jkm99JLUr59ne2xs+0yiAgB/Nm6c6/drU4tbbDYpLs7Vz9dCQ0M9nq9evVpr1qzR3Xffrbffflu7du3S5Zdfrtra2mbPc+rEV5vNprq6uhYfU7/y5+RjGrvtijesRm7TcvI5wsLCtHPnTm3cuFHR0dG67777NHLkSH333Xey2+3Ky8vT66+/rvPOO0+//e1vlZCQoJKSEq9q8IbfhRHJFTj27pXy86UNG1xfS0oIIgDQ1jrTiHRhYaGmTp2q2bNna+TIkTrnnHP0xRdf+LyOhIQEvf/++x5tO3bs8Ooc5513nrZt2+bRtn37dp177rmy/+uHHRAQoMsuu0yrVq3SRx99pL179+rtt9+W5ApDKSkpevDBB1VcXKzAwEC9/PLLZ/CumudXS3tPZrezfBcAfKF+RLqxfUaysjrOPwQHDRqkTZs2afv27erRo4cee+wxHThwQEOHDvVpHbfffrv+67/+S0lJSUpOTlZOTo4++ugjnXPOOS0+x6JFi/TjH/9YDz30kGbOnKl33nlHTzzxhLKzsyVJr732mvbs2aNLLrlEPXr00ObNm1VXV6eEhAS99957euutt5Samqo+ffrovffe09dff92uPwe/DSMAAN9JS5OmTnWtmqmocM0RGTeuY4yI1Lv33ntVUlKiyy+/XCEhIbrllls0bdo0VVVV+bSO6667Tnv27NEvfvELHTt2TDNmzNANN9zQYLSkOaNHj9aLL76o++67Tw899JCio6O1fPly3XDDDZKkyMhI5ebm6oEHHtCxY8c0ePBgbdy4UcOGDdPu3bu1detWZWVlqbq6WvHx8Vq9erUmT57cTu/Yz3ZgBQB4ry12YMWZmTRpkvr27avnn3/edCkNsAMrAABdzNGjR/Xkk0/q8ssvl91u18aNG/Xmm28qLy/PdGnthjACAEAHYrPZtHnzZj388MOqqalRQkKCNm3apMsuu8x0ae2GMAIAQAcSHBysN99803QZPuWXS3sBAEDHQRgBALRIJ1jvAAPa4nNBGAEANKt+t9D67cKBk9V/Lk7didYbzBkBADTLbrcrMjLSfe+UkJCQBluNw/9YlqWjR4+qsrJSkZGR7p1dW4MwAgA4rb59+0rSaW8AB/8TGRnp/ny0FmEEAHBaNptN0dHR6tOnj44fP266HHQQ3bt3P6MRkXqEEQBAi9nt9jb54wOcjAmsAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAo1oVRrKzszVw4EAFBQUpMTFRhYWFzfavqanRsmXLFB8fL4fDoR/96Ed65plnWlUwAADoWgK8PSAnJ0cZGRnKzs5WSkqKnnrqKU2ePFmffPKJ+vfv3+gxM2bM0D//+U89/fTTGjRokCorK3XixIkzLh4AAHR+NsuyLG8OGDNmjEaPHq21a9e624YOHapp06YpMzOzQf833nhD11xzjfbs2aOePXu2qsjq6mpFRESoqqpK4eHhrToHAADwrZb+/fbqMk1tba2KioqUmprq0Z6amqrt27c3esyrr76qpKQkrVq1Sv369dO5556rX/ziF/rhhx+afJ2amhpVV1d7PAAAQNfk1WWagwcPyul0KioqyqM9KipKBw4caPSYPXv2aNu2bQoKCtLLL7+sgwcP6uc//7m++eabJueNZGZm6sEHH/SmNAAA0Em1agKrzWbzeG5ZVoO2enV1dbLZbHrhhRd04YUXasqUKXrssce0fv36JkdHli5dqqqqKvejrKysNWUCAIBOwKuRkd69e8tutzcYBamsrGwwWlIvOjpa/fr1U0REhLtt6NChsixL+/bt0+DBgxsc43A45HA4vCkNAAB0Ul6NjAQGBioxMVF5eXke7Xl5eUpOTm70mJSUFO3fv1/ff/+9u+3zzz9Xt27dFBsb24qSAQBAV+L1ZZqFCxfqD3/4g5555hnt3r1bd955p0pLSzV//nxJrkss119/vbv/rFmz1KtXL91444365JNPtHXrVt11112aO3eugoOD2+6dAACATsnrfUZmzpypQ4cOafny5aqoqNDw4cO1efNmxcfHS5IqKipUWlrq7n/WWWcpLy9Pt99+u5KSktSrVy/NmDFDDz/8cNu9CwAA0Gl5vc+ICewzAgBA59Mu+4wAAAC0NcIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwKhWhZHs7GwNHDhQQUFBSkxMVGFhYZN9CwoKZLPZGjw+/fTTVhcNAAC6Dq/DSE5OjjIyMrRs2TIVFxdr3Lhxmjx5skpLS5s97rPPPlNFRYX7MXjw4FYXDQAAug6bZVmWNweMGTNGo0eP1tq1a91tQ4cO1bRp05SZmdmgf0FBgSZOnKhvv/1WkZGRLXqNmpoa1dTUuJ9XV1crLi5OVVVVCg8P96ZcAABgSHV1tSIiIk7799urkZHa2loVFRUpNTXVoz01NVXbt29v9tgLLrhA0dHRuvTSS5Wfn99s38zMTEVERLgfcXFx3pQJAAA6Ea/CyMGDB+V0OhUVFeXRHhUVpQMHDjR6THR0tNatW6dNmzYpNzdXCQkJuvTSS7V169YmX2fp0qWqqqpyP8rKyrwpEwAAdCIBrTnIZrN5PLcsq0FbvYSEBCUkJLifjx07VmVlZfr1r3+tSy65pNFjHA6HHA5Ha0oDAACdjFcjI71795bdbm8wClJZWdlgtKQ5F110kb744gtvXhoAAHRRXoWRwMBAJSYmKi8vz6M9Ly9PycnJLT5PcXGxoqOjvXlpAADQRXl9mWbhwoVKT09XUlKSxo4dq3Xr1qm0tFTz58+X5JrvUV5erueee06SlJWVpQEDBmjYsGGqra3VH//4R23atEmbNm1q23cCAAA6Ja/DyMyZM3Xo0CEtX75cFRUVGj58uDZv3qz4+HhJUkVFhceeI7W1tfrFL36h8vJyBQcHa9iwYfrLX/6iKVOmtN27AAAAnZbX+4yY0NJ1ygAAoONol31GAAAA2hphBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRrQoj2dnZGjhwoIKCgpSYmKjCwsIWHfe///u/CggI0KhRo1rzsgAAoAvyOozk5OQoIyNDy5YtU3FxscaNG6fJkyertLS02eOqqqp0/fXX69JLL211sQAAoOuxWZZleXPAmDFjNHr0aK1du9bdNnToUE2bNk2ZmZlNHnfNNddo8ODBstvteuWVV7Rr164Wv2Z1dbUiIiJUVVWl8PBwb8oFAACGtPTvt1cjI7W1tSoqKlJqaqpHe2pqqrZv397kcc8++6z+7//+T/fff3+LXqempkbV1dUeDwAA0DV5FUYOHjwop9OpqKgoj/aoqCgdOHCg0WO++OILLVmyRC+88IICAgJa9DqZmZmKiIhwP+Li4rwpEwAAdCKtmsBqs9k8nluW1aBNkpxOp2bNmqUHH3xQ5557bovPv3TpUlVVVbkfZWVlrSkTAAB0Ai0bqviX3r17y263NxgFqaysbDBaIkmHDx/Wjh07VFxcrNtuu02SVFdXJ8uyFBAQoL/97W/6yU9+0uA4h8Mhh8PhTWkAAKCT8mpkJDAwUImJicrLy/Noz8vLU3JycoP+4eHh+vjjj7Vr1y73Y/78+UpISNCuXbs0ZsyYM6seAAB0el6NjEjSwoULlZ6erqSkJI0dO1br1q1TaWmp5s+fL8l1iaW8vFzPPfecunXrpuHDh3sc36dPHwUFBTVoBwAA/snrMDJz5kwdOnRIy5cvV0VFhYYPH67NmzcrPj5eklRRUXHaPUcAAADqeb3PiAnsMwIAQOfTLvuMAAAAtDXCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKO8vmsv2o7TKRUWShUVUnS0NG6cZLebrgoAAN8ijBiSmystWCDt2/fvtthY6fHHpbQ0c3UBAOBrXKYxIDdXmj7dM4hIUnm5qz0310xdAACYQBjxMafTNSJiWQ2/V9+WkeHqBwCAPyCM+FhhYcMRkZNZllRW5uoHAIA/IIz4WEVF2/YDAKCzI4z4WHR02/YDAKCzI4z42LhxrlUzNlvj37fZpLg4Vz8AAPwBYcTH7HbX8l2pYSCpf56VxX4jAAD/QRgxIC1NeuklqV8/z/bYWFc7+4wAAPwJm54ZkpYmTZ3KDqwAABBGDLLbpQkTTFcBAIBZXKYBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARrUqjGRnZ2vgwIEKCgpSYmKiCgsLm+y7bds2paSkqFevXgoODtaQIUO0Zs2aVhcMAAC6lgBvD8jJyVFGRoays7OVkpKip556SpMnT9Ynn3yi/v37N+gfGhqq2267Teeff75CQ0O1bds2zZs3T6Ghobrlllva5E0AAIDOy2ZZluXNAWPGjNHo0aO1du1ad9vQoUM1bdo0ZWZmtugcaWlpCg0N1fPPP9+i/tXV1YqIiFBVVZXCw8O9KRcAABjS0r/fXl2mqa2tVVFRkVJTUz3aU1NTtX379hado7i4WNu3b9f48eOb7FNTU6Pq6mqPBwAA6Jq8CiMHDx6U0+lUVFSUR3tUVJQOHDjQ7LGxsbFyOBxKSkrSrbfeqptvvrnJvpmZmYqIiHA/4uLivCkTAAB0Iq2awGqz2TyeW5bVoO1UhYWF2rFjh5588kllZWVp48aNTfZdunSpqqqq3I+ysrLWlAkAADoBryaw9u7dW3a7vcEoSGVlZYPRklMNHDhQkjRixAj985//1AMPPKBrr7220b4Oh0MOh8Ob0gAAQCfl1chIYGCgEhMTlZeX59Gel5en5OTkFp/HsizV1NR489IAAKCL8npp78KFC5Wenq6kpCSNHTtW69atU2lpqebPny/JdYmlvLxczz33nCTpd7/7nfr3768hQ4ZIcu078utf/1q33357G74NAADQWXkdRmbOnKlDhw5p+fLlqqio0PDhw7V582bFx8dLkioqKlRaWuruX1dXp6VLl6qkpEQBAQH60Y9+pEcffVTz5s1ru3eBVnE6pcJCqaJCio6Wxo2T7HbTVQEA/I3X+4yYwD4jbS83V1qwQNq3799tsbHS449LaWnm6gIAdB3tss8IuobcXGn6dM8gIknl5a723FwzdQEA/BNhxM84na4RkcbGw+rbMjJc/QAA8AXCiJ8pLGw4InIyy5LKylz9AADwBcKIn6moaNt+AACcKcKIn4mObtt+AACcKcKInxk3zrVqpqnd+202KS7O1Q8AAF8gjPgZu921fFdqGEjqn2dlsd8IAMB3CCN+KC1NeuklqV8/z/bYWFc7+4wAAHzJ6x1Y0TWkpUlTp7IDKwDAPMKIH7PbpQkTTFcBAPB3XKYBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRhBAAAGEUYAQAARhFGAACAUYQRAABgFGEEAAAYxY3yYIzTyV2DAQCEERiSmystWCDt2/fvtthY6fHHpbQ0c3UBAHyPyzTwudxcafp0zyAiSeXlrvbcXDN1AQDMIIzAp5xO14iIZTX8Xn1bRoarHwDAPxBG4FOFhQ1HRE5mWVJZmasfAMA/EEbgUxUVbdsPAND5EUbgU9HRbdsPAND5EUbgU+PGuVbN2GyNf99mk+LiXP0AAP6BMAKfsttdy3elhoGk/nlWFvuNAIA/IYzA59LSpJdekvr182yPjXW1s88IAPgXNj2DEWlp0tSp7MAKACCMwCC7XZowwXQVAADTuEwDAACMIowAAACjCCMAAMAowggAADCKMAIAAIxiNQ38ltPJ0mIA6AgII/BLubnSggWedxCOjXXtDsumawDgW1ymgd/JzZWmT/cMIpJUXu5qz801UxcA+CvCCPyK0+kaEbGsht+rb8vIcPUDAPgGYQR+pbCw4YjIySxLKitz9QMA+Earwkh2drYGDhyooKAgJSYmqrCZ39y5ubmaNGmSzj77bIWHh2vs2LH661//2uqCgTNRUdG2/QAAZ87rMJKTk6OMjAwtW7ZMxcXFGjdunCZPnqzS0tJG+2/dulWTJk3S5s2bVVRUpIkTJ+qqq65ScXHxGRcPeCs6um37AQDOnM2yGrt63rQxY8Zo9OjRWrt2rbtt6NChmjZtmjIzM1t0jmHDhmnmzJm67777WtS/urpaERERqqqqUnh4uDflAh6cTmnAANdk1cY++Taba1VNSQnLfAHgTLX077dXIyO1tbUqKipSamqqR3tqaqq2b9/eonPU1dXp8OHD6tmzZ5N9ampqVF1d7fEA2oLd7lq+K7mCx8nqn2dlEUQAwJe8CiMHDx6U0+lUVFSUR3tUVJQOHDjQonOsXr1aR44c0YwZM5rsk5mZqYiICPcjLi7OmzKBZqWlSS+9JPXr59keG+tqZ58RAPCtVm16Zjvln5SWZTVoa8zGjRv1wAMP6M9//rP69OnTZL+lS5dq4cKF7ufV1dUEErSptDRp6lR2YAWAjsCrMNK7d2/Z7fYGoyCVlZUNRktOlZOTo5tuukn//d//rcsuu6zZvg6HQw6Hw5vSAK/Z7dKECaarAAB4dZkmMDBQiYmJysvL82jPy8tTcnJyk8dt3LhRN9xwgzZs2KArrriidZUCXYzTKRUUSBs3ur6y0RoAf+X1ZZqFCxcqPT1dSUlJGjt2rNatW6fS0lLNnz9fkusSS3l5uZ577jlJriBy/fXX6/HHH9dFF13kHlUJDg5WREREG74VoPPg3jgA8G9e7zMyc+ZMZWVlafny5Ro1apS2bt2qzZs3Kz4+XpJUUVHhsefIU089pRMnTujWW29VdHS0+7FgwYK2exdAJ8K9cQDAk9f7jJjAPiPoKur3OWlqS3r2OQHQlbTLPiMAzgz3xgGAhggjgA9xbxwAaIgwAvgQ98YBgIYII4APjRvnmhPS1B6BNpsUF+fqBwD+gjAC+BD3xgGAhggjgI9xbxwA8NSqe9MAODMd5d44Tqf5GgCAMAIYYvreOOwCC6Cj4DIN4IfYBRZAR0IYAfyM0+kaEWls7+X6towMbtwHwHcII4CfYRdYAB0NYQTwM+wCC6CjIYwAfoZdYAF0NIQRwM+wCyyAjoYwAvgZdoEF0NEQRgA/1FF2gXU6pYICaeNG11dW8AD+iU3PAD9lehdYNl0DUM9mWY3tNtCxVFdXKyIiQlVVVQoPDzddDoAzVL/p2qm/feovE3GPHqBraOnfby7TAPApNl0DcCrCCACfYtM1AKcijADwKTZdA3AqwggAn2LTNQCnYjUNAJ+q33StvLzxeSM2m+v7vth0zek0t5oIwL8xMgLApzrKpmu5udKAAdLEidKsWa6vAwa42gH4FmEEgM+Z3nStfmnxqRNpy8td7QQSwLfYZwSAMSYukzidrhGQplb01F8mKinhkg1wplr695s5IwCMsdulCRN8+5reLC32dW2Av+IyDQC/wtJioOMhjADwKywtBjoeLtMA8CssLQY6HkZGAPgVlhYDHQ9hBIDfYWkx0LGwtBeA32JpMdC+WNoLAKfB0mKgY+AyDQD4EEuLgYYYGQEAH+pIS4tZzYOOgpERAPCh+qXFp67kqWezSXFx7b+0mNU86EgIIwDgQx1haTGredDREEYAwMdMLi12OqUFCxrf8K2+LSPD1Q/wFeaMAIABaWnS1Km+n7PBah50RIQRADDExNLijraah0m0kAgjAOBXOtJqntxc1yWjk0dqYmNdc2raexdcdCzMGQEAP9KRVvMwiRb1CCMA4Ec6wmoeJtHiVIQRAPAzpm8U6M0kWviHVoWR7OxsDRw4UEFBQUpMTFRhM5+YiooKzZo1SwkJCerWrZsyMjJaWysAoI2kpUl790r5+dKGDa6vJSW+mavR0SbRwjyvw0hOTo4yMjK0bNkyFRcXa9y4cZo8ebJKS0sb7V9TU6Ozzz5by5Yt08iRI8+4YABA26hfzXPtta6vvlrF0pEm0TqdUkGBtHGj6yuXhsywWVZjV+2aNmbMGI0ePVpr1651tw0dOlTTpk1TZmZms8dOmDBBo0aNUlZWlldFtvQWxACAjs/pdG09X17e+LwRm811yaikpP13omU1T/tq6d9vr0ZGamtrVVRUpNTUVI/21NRUbd++vXWVNqKmpkbV1dUeDwBA19ARJtGymqdj8SqMHDx4UE6nU1FRUR7tUVFROnDgQJsVlZmZqYiICPcjLi6uzc4NADCPLfFxslZNYLWdEmUty2rQdiaWLl2qqqoq96OsrKzNzg0A6BhMTaJlNU/H49UOrL1795bdbm8wClJZWdlgtORMOBwOORyONjsfAKBj8vct8dkO38WrkZHAwEAlJiYqLy/Poz0vL0/JycltWhgAAO2ho6zmyc11TeSdOFGaNcv1dcAA/5yv4vW9aRYuXKj09HQlJSVp7NixWrdunUpLSzV//nxJrkss5eXleu6559zH7Nq1S5L0/fff6+uvv9auXbsUGBio8847r23eBQAALVS/Jf7pVvO055b49RNoT339+gm0vth8riPxOozMnDlThw4d0vLly1VRUaHhw4dr8+bNio+Pl+Ta5OzUPUcuuOAC938XFRVpw4YNio+P1969e8+segAAvFS/mmf6dFfwODkQ+GI1z+km0Npsrgm0U6f6zyUbr/cZMYF9RgAAba2xfUbi4lxBpD1HJQoKXJdkTic/v/3n07T3nJWW/v32emQEAICuIC3NNfrg6wmkHWUCbUfa9I0wAgDwWyZW83SECbQdbc4Kd+0FAMCH6ifQNrU9l83mulzUXhNoO+Kmb4QRAAB8yPR2+B1x0zfCCAAAPmZyO/yOMmflZMwZAQDAAFMTaDvCnJVTEUYAADDExATajrDp26m4TAMAgB8xPWelMYQRAAD8jMk5K43hMg0AAH7I1JyVxhBGAADwUybmrDSGyzQAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAqE6xA6v1r9sKVldXG64EAAC0VP3fbaux2wOfpFOEkcOHD0uS4uLiDFcCAAC8dfjwYUVERDT5fZt1urjSAdTV1Wn//v0KCwuT7dT7HXdy1dXViouLU1lZmcLDw02X43O8f/9+/xI/A39//xI/g678/i3L0uHDhxUTE6Nu3ZqeGdIpRka6deum2NhY02W0q/Dw8C73IfQG79+/37/Ez8Df37/Ez6Crvv/mRkTqMYEVAAAYRRgBAABGEUYMczgcuv/+++VwOEyXYgTv37/fv8TPwN/fv8TPwN/fv9RJJrACAICui5ERAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYcSAzMxM/fjHP1ZYWJj69OmjadOm6bPPPjNdljGZmZmy2WzKyMgwXYpPlZeXa/bs2erVq5dCQkI0atQoFRUVmS7LJ06cOKF77rlHAwcOVHBwsM455xwtX75cdXV1pktrN1u3btVVV12lmJgY2Ww2vfLKKx7ftyxLDzzwgGJiYhQcHKwJEyboH//4h5li20Fz7//48eNavHixRowYodDQUMXExOj666/X/v37zRXcDk73GTjZvHnzZLPZlJWV5bP6TCKMGLBlyxbdeuutevfdd5WXl6cTJ04oNTVVR44cMV2az33wwQdat26dzj//fNOl+NS3336rlJQUde/eXa+//ro++eQTrV69WpGRkaZL84mVK1fqySef1BNPPKHdu3dr1apV+tWvfqXf/va3pktrN0eOHNHIkSP1xBNPNPr9VatW6bHHHtMTTzyhDz74QH379tWkSZPcNwrt7Jp7/0ePHtXOnTt17733aufOncrNzdXnn3+un/70pwYqbT+n+wzUe+WVV/Tee+8pJibGR5V1ABaMq6ystCRZW7ZsMV2KTx0+fNgaPHiwlZeXZ40fP95asGCB6ZJ8ZvHixdbFF19sugxjrrjiCmvu3LkebWlpadbs2bMNVeRbkqyXX37Z/byurs7q27ev9eijj7rbjh07ZkVERFhPPvmkgQrb16nvvzHvv/++Jcn66quvfFOUjzX1M9i3b5/Vr18/6+9//7sVHx9vrVmzxue1mcDISAdQVVUlSerZs6fhSnzr1ltv1RVXXKHLLrvMdCk+9+qrryopKUlXX321+vTpowsuuEC///3vTZflMxdffLHeeustff7555KkDz/8UNu2bdOUKVMMV2ZGSUmJDhw4oNTUVHebw+HQ+PHjtX37doOVmVNVVSWbzeY3o4WS6w716enpuuuuuzRs2DDT5fhUp7hrb1dmWZYWLlyoiy++WMOHDzddjs/86U9/0s6dO/XBBx+YLsWIPXv2aO3atVq4cKF++ctf6v3339cdd9whh8Oh66+/3nR57W7x4sWqqqrSkCFDZLfb5XQ69cgjj+jaa681XZoRBw4ckCRFRUV5tEdFRemrr74yUZJRx44d05IlSzRr1qwueRfbpqxcuVIBAQG64447TJfic4QRw2677TZ99NFH2rZtm+lSfKasrEwLFizQ3/72NwUFBZkux4i6ujolJSVpxYoVkqQLLrhA//jHP7R27Vq/CCM5OTn64x//qA0bNmjYsGHatWuXMjIyFBMTozlz5pguzxibzebx3LKsBm1d3fHjx3XNNdeorq5O2dnZpsvxmaKiIj3++OPauXOn3/1vLjGB1ajbb79dr776qvLz8xUbG2u6HJ8pKipSZWWlEhMTFRAQoICAAG3ZskW/+c1vFBAQIKfTabrEdhcdHa3zzjvPo23o0KEqLS01VJFv3XXXXVqyZImuueYajRgxQunp6brzzjuVmZlpujQj+vbtK+nfIyT1KisrG4yWdGXHjx/XjBkzVFJSory8PL8aFSksLFRlZaX69+/v/r341VdfadGiRRowYIDp8todIyMGWJal22+/XS+//LIKCgo0cOBA0yX51KWXXqqPP/7Yo+3GG2/UkCFDtHjxYtntdkOV+U5KSkqD5dyff/654uPjDVXkW0ePHlW3bp7/FrLb7V16aW9zBg4cqL59+yovL08XXHCBJKm2tlZbtmzRypUrDVfnG/VB5IsvvlB+fr569epluiSfSk9PbzB/7vLLL1d6erpuvPFGQ1X5DmHEgFtvvVUbNmzQn//8Z4WFhbn/NRQREaHg4GDD1bW/sLCwBvNjQkND1atXL7+ZN3PnnXcqOTlZK1as0IwZM/T+++9r3bp1WrdunenSfOKqq67SI488ov79+2vYsGEqLi7WY489prlz55ourd18//33+vLLL93PS0pKtGvXLvXs2VP9+/dXRkaGVqxYocGDB2vw4MFasWKFQkJCNGvWLINVt53m3n9MTIymT5+unTt36rXXXpPT6XT/XuzZs6cCAwNNld2mTvcZODWAde/eXX379lVCQoKvS/U9w6t5/JKkRh/PPvus6dKM8belvZZlWf/zP/9jDR8+3HI4HNaQIUOsdevWmS7JZ6qrq60FCxZY/fv3t4KCgqxzzjnHWrZsmVVTU2O6tHaTn5/f6P/v58yZY1mWa3nv/fffb/Xt29dyOBzWJZdcYn388cdmi25Dzb3/kpKSJn8v5ufnmy69zZzuM3Aqf1raa7Msy/JR7gEAAGiACawAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACM+n/+9UZ4juRZlQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = [word2idx.get(word, 1) for word in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', x)\n",
    "print('Sentence word indexes', sentence_word_idxs)\n",
    "# Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
    "# Sentence word indexes tensor([358640, 373606, 343335, 245002,      1,    873])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sentence_word_idxs_tensor = torch.tensor(sentence_word_idxs)\n",
    "sent_chunk_predictions = model1(sentence_word_idxs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape\n",
    "#torch.Size([6, 23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2079e-13, 1.8017e-07, 1.2052e-05, 3.4607e-10, 2.6389e-08, 2.1298e-06,\n",
       "        9.9995e-01, 1.0460e-06, 3.4159e-08, 3.6748e-07, 2.9091e-15, 8.2161e-10,\n",
       "        2.7258e-09, 6.4365e-09, 1.3882e-09, 4.9181e-10, 1.9671e-06, 3.5363e-09,\n",
       "        4.1119e-13, 1.6465e-10, 4.9549e-09, 9.3513e-10, 3.2534e-05],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)\n",
    "# tensor([1.2072e-13, 4.7664e-10, 3.5222e-09, 7.4905e-13, 8.2765e-10, 9.5403e-09,\n",
    "#         1.0000e+00, 9.4836e-10, 3.9878e-12, 4.5347e-09, 1.2401e-11, 1.8891e-13,\n",
    "#         1.4451e-13, 1.7238e-13, 1.3286e-12, 2.0025e-11, 9.5634e-09, 1.7781e-12,\n",
    "#         1.2139e-11, 2.6272e-12, 5.4331e-11, 9.5586e-15, 1.6024e-06],\n",
    "#        grad_fn=<SoftmaxBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 16, 11, 21, 22])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)\n",
    "#tensor([ 6, 16, 16, 11, 21, 22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(x[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))\n",
    "\n",
    "# the: B-NP\n",
    "# united: I-NP\n",
    "# states: I-NP\n",
    "# might: B-VP\n",
    "# collapsez /ukn: I-VP\n",
    "# .: O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]\n",
    "\n",
    "# [[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
    "#   {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
    "#   {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
    "#   {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
    "#   {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
    "#   {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
    "#   {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
    "#   {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
    "#   {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
    "#   {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
    "#   {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
    "#   {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
    "#   {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
    "#   {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
    "#   {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
    "#   {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
    "#   {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])\n",
    "\n",
    "# X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
    "# Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    x_new = []\n",
    "    for word in x:\n",
    "        x_new += [word2idx.get(word, 1)]\n",
    "    X_test_idx += [x_new]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])\n",
    "\n",
    "# X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
    "#          17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
    "#              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "#              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "#              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "#              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "#              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "#              0,      0,      0,      0,      0,      0,      0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape\n",
    "#torch.Size([2012, 70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = model1(X_test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[-16.4449,  -5.4258,  -5.2880,  ...,  -4.9341,  -6.2109,  -1.3287],\n",
      "        [-18.7449,  -8.5742,  -3.8617,  ...,  -7.8036,  -3.2569,   0.6076],\n",
      "        [-20.7515,  -5.9800,  -4.8244,  ...,  -8.3807,  -7.4858,   0.7073],\n",
      "        ...,\n",
      "        [ -7.6374,  -1.9386,  -3.2933,  ..., -10.4957,  -3.8585,   4.3897],\n",
      "        [ -7.0070,  -1.7842,  -3.2046,  ..., -10.1718,  -3.7411,   4.1230],\n",
      "        [ -6.4155,  -1.6197,  -3.1276,  ...,  -9.9474,  -3.7133,   3.9679]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])\n",
    "\n",
    "# Predictions tensor([[ -7.0167,  -1.3971,  -2.6404,  ...,  -1.0799,  -1.3150,   4.7549],\n",
    "#         [ -6.5066,  -4.5663,   1.0363,  ...,  -2.3344,   6.9481,   6.8664],\n",
    "#         [-11.6368,  -2.9430,  -2.0845,  ...,  -4.6665,  -7.5087,   6.0453],\n",
    "#         ...,\n",
    "#         [ 20.2845,  -4.0088,  -3.6083,  ...,  -1.0157,  -5.1971,   0.3017],\n",
    "#         [ 18.3593,  -3.3927,  -3.4281,  ...,  -0.7486,  -4.9716,  -0.0463],\n",
    "#         [ 16.9232,  -2.7952,  -3.0611,  ...,  -0.5927,  -4.9505,  -0.2680]],\n",
    "#        grad_fn=<SelectBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-SBAR'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]\n",
    "\n",
    "# [{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
    "#  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
    "#  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
    "#  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
    "#  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
    "#  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
    "#  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
    "#  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
    "#  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
    "#  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
    "#  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
    "#  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
    "#  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
    "#  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
    "#  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
    "#  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
    "#  {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8976712243241556"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score\n",
    "#0.9000020716372148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
